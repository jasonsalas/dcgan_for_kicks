{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep convolutional generative adversarial networks (DCGANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An artificial intelligence exercise pitting authentic versus synthetic imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an experiment for producing completely artificial images or shoes through a DCGAN, based on [the wonderful repo](https://github.com/CShorten/BballShoesDCGANs/blob/master/Kicks_DCGAN.ipynb) and [blog post](https://medium.com/@connorshorten300/generating-basketball-shoes-with-dcgans-6cd72d521c01) by Dr. Connor Shorten (Github: [@CShorten](https://github.com/CShorten)). Rather than use the shipped datasets like MNIST and CIFAR-10, Connor uses a custom dataset of basketball shoes, which I sneakily found [hiding on his profile page](https://github.com/CShorten/NIKE_vs_ADIDAS) in [training](https://github.com/CShorten/NIKE_vs_ADIDAS/tree/master/TRAIN) and [testing](https://github.com/CShorten/NIKE_vs_ADIDAS/tree/master/TEST) sets. \n",
    "\n",
    "His project uses a number of shoe images based on the same general style, with varying colors, which he trains a DCGAN on to produce custom designs. It's a really neat concept, and a much more practical example for grabbing real-world data that needs to be preprocessed and massaged. The source images also were larger and in color, as opposed to MNIST's (50000 28, 28, 1) shape. It wasn't at all hard.\n",
    "\n",
    "So as a clever twist to get the bespoke dataset into a format that the DCGAN expects - a NumPy shape of (140, 45, 45, 3) - the images needed to be decomposed to their raw pixel values, and then persisted by storing them as an array in NumPy's uncompressed NPZ format. The 140 images Connor uses with both the testing and training sets combined come out to 1.6MB on disk.\n",
    "\n",
    "I upscaled the demo [on Google Colab](https://colab.research.google.com/drive/12tPO5nwTgAtQHCWugo72CuZJOa1rLneD) to make use of cloud GPUs and make the machine learning run consist of many more epochs, hopefully to get both the DCGAN's generator and discriminator models to converge (or get close to it). I used Google Drive File Stream to access the .npz file on disk in my share space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import warnings\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, BatchNormalization, Activation, Conv2D, Conv2DTranspose, LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shoes = []\n",
    "DIR = './images'\n",
    "\n",
    "for filename in os.listdir(DIR):\n",
    "#     image = cv2.imread(os.path.join(DIR, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.imread(os.path.join(DIR, filename))\n",
    "    image = cv2.resize(image, (45, 45))\n",
    "    \n",
    "    shoes.append(image)\n",
    "\n",
    "shoes_raw_pixels = np.array(shoes)\n",
    "np.savez('shoes.npz', shoes_raw_pixels)\n",
    "print('shoes shape', shoes_raw_pixels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' UNCOMMENT THIS CELL *ONLY* WHEN RUNNING THIS NOTEBOOK ON GOOGLE COLAB '''\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# shoes_data = np.load('/content/drive/My Drive/data_science/shoes.npz')\n",
    "# print(shoes_data['arr_0'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the array & verify that it persisted with the correct dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data = np.load('shoes.npz')\n",
    "\n",
    "plt.imshow(shoes_data['arr_0'][42, :, :, 0], cmap='nipy_spectral')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK! So far, so good - now let's build the GAN..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the generator and discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 45\n",
    "img_cols = 45\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "z_dim = 100\n",
    "init = initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "def build_generator(img_shape, z_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256*5*5, input_dim=z_dim, kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((5, 5, 256)))\n",
    "    \n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2DTranspose(3, kernel_size=3, strides=2, activation='tanh'))\n",
    "    \n",
    "    z = Input(shape=(z_dim, ))\n",
    "    img = model(z)\n",
    "    \n",
    "    return Model(inputs=z, outputs=img)\n",
    "\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, kernel_initializer=init))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(96, kernel_size=3, strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    img = Input(shape=img_shape)\n",
    "    prediction = model(img)\n",
    "    \n",
    "    return Model(inputs=img, outputs=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the discriminator, freeze its layers, then combine the models for the DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "generator = build_generator(img_shape, z_dim)\n",
    "z = Input(shape=(100, ))\n",
    "img = generator(z)\n",
    "\n",
    "discriminator.trainable = False\n",
    "prediction = discriminator(img)\n",
    "\n",
    "gan = Model(inputs=z, outputs=prediction)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the machine learning method and backpropagate the gradient, updating the weights in the generator only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "    # ------------------\n",
    "    # PRE-PROCESSING\n",
    "    # ------------------\n",
    "    \n",
    "    # use the first np.npz.files array as the training set of the raw pixel data\n",
    "    X_train = shoes_data['arr_0']\n",
    "    \n",
    "    # scale the training data to the hyperbolic tangent range: [-1, 1]\n",
    "    X_train = (X_train.astype('float32') / 127.5) - 1.0\n",
    "    \n",
    "    # ------------------\n",
    "    # LABELS PREPARATION\n",
    "    # ------------------\n",
    "    labels_authentic = np.ones((batch_size, 1))\n",
    "    labels_synthetic = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        # produce a random batch of images from the training data\n",
    "        index = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        images_authentic = X_train[index]\n",
    "        \n",
    "        # produce a collection of fake images based on random noise\n",
    "        z_noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        images_synthetic = generator.predict(z_noise)\n",
    "\n",
    "        # compute the discriminator model's loss\n",
    "        d_loss_authentic = discriminator.train_on_batch(images_authentic, labels_authentic)\n",
    "        d_loss_synthetic = discriminator.train_on_batch(images_synthetic, labels_synthetic)\n",
    "        d_loss = 0.5 * np.add(d_loss_authentic, d_loss_synthetic)\n",
    "        \n",
    "        # produce a new crop of fake images based on random noise\n",
    "        z_noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        images_synthetic = generator.predict(z_noise)\n",
    "        \n",
    "        # compute the generator model's loss\n",
    "        # based on the combined GAN network model\n",
    "        # the discriminator's losses are frozen and  \n",
    "        # backpropagate through to update the generator \n",
    "        # NOTE: the GAN is learning gradients based on random noise and real labels\n",
    "        g_loss = gan.train_on_batch(z_noise, labels_authentic)\n",
    "        \n",
    "        if iteration % sample_interval == 0:\n",
    "            print('> %d [D loss: %f accuracy: %.2f%%] [G loss: %f]' % (iteration, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            losses.append((d_loss[0], g_loss))\n",
    "            accuracies.append(100*d_loss[1])\n",
    "            sample_images(iteration)\n",
    "            \n",
    "def sample_images(iteration, rows=4, cols=4):\n",
    "    # create images to challennge the discriminator\n",
    "    z_noise = np.random.normal(0, 1, (rows*cols, z_dim))\n",
    "    images_synthetic = generator.predict(z_noise)\n",
    "    \n",
    "    # rescale images back to the range [1, 1]\n",
    "    images_synthetic = 0.5 * images_synthetic + 0.5\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4, 4), sharey=True, sharex=True)\n",
    "    count = 0\n",
    "    \n",
    "    # plot images produced by the generator\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            axes[i, j].imshow(images_synthetic[count, :, :, 0], cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good to go! Let's set hyperparameters and run this sucker! (You might want to grab a cup off coffee for this part...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "batch_size = 128\n",
    "sample_interval = 1000\n",
    "\n",
    "start = time.time()\n",
    "train(iterations, batch_size, sample_interval)\n",
    "print('[INFO] completed training in {} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How'd we do in the loss department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and accuracy metrics\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(losses[0])\n",
    "plt.plot(losses[1])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Discriminator', 'Generator'], loc='center right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
